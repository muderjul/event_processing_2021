To facilitate the explanation we focus on six different parts of our implementation:
\begin{enumerate}
  \item Dataset Generation
  \item main.py
  \item Windowing Library
  \item Reactive Aggregator
  \item FlatFAT
  \item Aggregation Operations
\end{enumerate}

These six parts make up all of the non-trivial components and are arranged from high
to low-level order.

Before we ran any tests, we tried to identify the different kinds of data streams we
would need. We decided to stick with 4 different data sets which will be explained further
in the Data Generation section.

Our experimental pipeline flows through all of the mentioned components, with the main
method being the entrypoint and defining our test cases, the Windowing Library reading
our generated data streams from file, passing all information to the Reactive Aggregator
all while measuring the time spent in the RA and performing some minor housekeeping tasks
for keeping the sliding window in place.
The Reactive Aggregator was mainly implemented as a wrapper around the FlatFAT with some extra checks
and the FlatFAT performs all aggregation operations on the sliding window.

The source code, data, and all figures have been made available at \url{https://github.com/muderjul/event\_processing\_2021}.

\subsection{Data Generation}
\label{sec:dg}

\subfile{data_generation.tex}


\subsection{main.py}
We implemented our main method in a way that allows us to run a lot of tests sequentially
and quickly give us information on how those turned out as well as show the progress of the
currently running tests without cluttering the output.
Additionally, we included a wrapper for coordinating a test with fixed window sizes due
to a possible bug in our implementation that lead to our FlatFAT being full while trying
to add more tuples which lead to the FlatFAT resizing to twice the size and therefore
losing a lot of speed due to unnecessary array length.

\subsection{Windowing Library}
We implemented our windowing library to provide the FlatFAT with our previously generated
data streams in a manageable format. We focused mainly on utility over speed since we
decided to only measure time spent in the Reactive Aggregator.
Measuring time was therefore also implemented in the windowing library, including a
180-second test timeout to speed up the runs of the full test suite. The windowing library
ensures that we keep track of all events which are currently contained in the FlatFAT
and are able to provide the necessary calls to \textit{insert, trigger} and \textit{evict}.

\subsection{Reactive Aggregator}
Since the scope of our implementation was limited to the ArgMax aggregation function,
our reactive aggregator is rather basic. We mainly interfaced the methods of FlatFAT
and added additional checks for resizing the tree when necessary as outlined in the paper.

\subsection{FlatFAT}
The FlatFAT is the core of our implementation. We decided to implement the binary tree
as a list using the knowledge about the amount of nodes in a full binary tree to determine
which index in the list represents which node and which indices represent leaves.

In addition to the public functions \texttt{update, aggregate, prefix} and \texttt{suffix} we
added the internal function \texttt{combine} for updating only changed parts of the tree
efficiently in case of a call to \texttt{new} or \texttt{update}. The main difference between
\texttt{update} and \texttt{new} is that \texttt{new} will disregard some checks that are necessary for
the update function, we will omit further explanation for brevity here.

\subsubsection{prefix, suffix and aggregate}
Since we limited our scope to FIFO and events being in order we decided to omit
front and back of buffer pointers as well as the compact function and use any free
space in the leaf-part of the list. Unfortunately this also means that we need
to search for this free space in the list which is our most expensive operation.
This means that \texttt{prefix(n)} returns the aggregated value (in our case ArgMax) of the
first $n$ entries while \texttt{suffix(n)} returns the aggregated value of the last $n$ entries
similarly. Note that this does not represent the newest and oldest entries but simply
first and last as ordered internally.
\texttt{aggregate} will in turn return only the root entry which always holds the aggregated
value over all leaves.

\subsubsection{update}
The update function handles a batch of either \textit{insert, evict} or \textit{trigger}
calls. For any $insert$ call we simply search for the first empty space
(encoded with \texttt{None})
while for any $trigger$ and $evict$ call we simply search for the first (and only) occurrence of
an entry with matching argument. Once we found the correct spot in our list we
update it accordingly and add this index to a list of updated indices which we will
pass to \texttt{combine} once all new tuples have been taken care of.


\subsubsection{combine}
The combine function handles all calls to the combine function and ensures that all
intermediate results are always up to date. Note that all indices passed to combine
are assumed to be of leaves (i.e. first leaf has index 0). It then runs through the
levels of the tree in a bottom-up manner updating entries only when necessary as
marked by the passed indices. This allows for quick and precise updates.

\subsection{Aggregation Operations}
Since we limited our scope to ArgMax these are very basic and hard-coded. With \texttt{lift(a)}
transforming an input event a into our internal dict format, \texttt{combine(a, b)} returning ArgMax(a, b)
and \texttt{lower(a)} returning Arg(a) for two dict objects a and b
