For our evaluation we decided to mirror the papers evaluation as closely as possible
to see if we were able to replicate the results obtained there.
Therefore our baseline is the given implementation of RA in the paper.
Although we compare ourselves to the other implementation we decided to focus on
replicating the asymptotic results rather than beating the raw performance of their implementation.

\subsection{Experimental Setup}
As already mentioned we want to evaluate similarly to the paper, which means we also mostly varied
window sizes and used sliding granularity of 1 where not specified.
Further information on our data streams can be taken from our Data Generation section \ref{sec:dg}.
To limit the tests and to gain the possibility of rerunning the tests with different configurations
and iterations of our implementation we limited ourselves to 5 million tuples and
a cap of 180 seconds spend only inside our reactive aggregator per run
which sums up to a maximum just short of 6 hours per run of the full evaluation suite.
We ran all tests on a 4-core 2.3 Ghz Intel Core i7 with 32 GB of RAM, using
Python 3.7.3 and MacOS 10.15.7

\subsection{Results and Analysis}
Since we were interested in replicating the papers results, we decided to
recreate figures (in the paper) 6, 8 and 10. Tables 3 and 4 as well as figure 11 were not suited
for such a comparison while our data sets were not able to guarantee the necessary
(1, 1)-changes for figure 7. Due to the previously mentioned possible bugs in our
implementation we decided to not replicate figure 9. We omitted comparing to figure 12
to keep our focus on the speed of the implementation instead of a memory footprint.

\subsubsection{Comparison for window aggregation from scratch}

\subfile{../figures/figure8.tex}

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{../figures/fig8}
	\caption{Figure 8 in~\cite{GeneralIncremental15} - Time in microseconds to aggregate the whole window from scratch for different window sizes}
	\label{fig:original_architecture}
\end{figure}

For replicating this figure we had almost no expectations. We knew beforehand that
our runtimes would not reach those of the RA from the paper. Nevertheless we decided
to include it as a sort of baseline of our comparison. We were able to reproduce the
exponential growth that can be seen in the paper but even roughly comparing the
values shows that our runtimes are much worse. In fact we see that our time is already
more than 50 times worse for window size 1024, even increasing to 245 times for 8192.

\subsubsection{Comparison for throughput}

\subfile{../figures/figure6.tex}

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{../figures/fig6}
	\caption{Figure 8 in~\cite{GeneralIncremental15} - Throughput in million tuples per second for different window sizes}
	\label{fig:original_architecture}
\end{figure}

\subsubsection{Comparison for average per-tuple cost}

\subfile{../figures/figure10.tex}

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{../figures/fig10}
	\caption{Figure 10 in~\cite{GeneralIncremental15} -  Average tuple cost in microseconds for different sliding granularities and window sizes}
	\label{fig:original_architecture}
\end{figure}
